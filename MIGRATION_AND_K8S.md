# ğŸ—ï¸ Migration Monolithe â†’ Microservices et Architecture Kubernetes

> Ce document dÃ©taille l'Ã©volution architecturale de LifyTP, passant d'une API monolithique Ã  une architecture microservices dÃ©ployÃ©e sur Kubernetes.

---

## ğŸ“‹ Table des MatiÃ¨res

- [Contexte et Objectifs](#-contexte-et-objectifs)
- [Architecture Avant/AprÃ¨s](#-architecture-avantaprÃ¨s)
- [DÃ©coupage en Microservices](#-dÃ©coupage-en-microservices)
- [Communication Inter-Services](#-communication-inter-services)
- [Dockerisation](#-dockerisation)
- [Architecture Kubernetes](#-architecture-kubernetes)
- [CI/CD Pipeline](#-cicd-pipeline)
- [DÃ©monstrations](#-dÃ©monstrations)
- [DifficultÃ©s et Solutions](#-difficultÃ©s-et-solutions)

---

## ğŸ¯ Contexte et Objectifs

### Contexte Initial

LifyTP est une application sociale de gestion d'Ã©vÃ©nements avec :
- Authentification utilisateurs
- Gestion d'Ã©vÃ©nements et calendrier
- Messagerie temps rÃ©el
- SystÃ¨me de follow/followers
- Feed social

### Objectifs de la Migration

| Objectif | BÃ©nÃ©fice |
|----------|----------|
| **ScalabilitÃ©** | Scaling indÃ©pendant par service |
| **Haute DisponibilitÃ©** | Replicas + auto-healing |
| **DÃ©ploiement Continu** | Rolling updates sans downtime |
| **Isolation** | DÃ©faillance d'un service n'impacte pas les autres |
| **MaintenabilitÃ©** | Code sÃ©parÃ© par domaine mÃ©tier |

---

## ğŸ”„ Architecture Avant/AprÃ¨s

### AVANT : API Monolithique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API MONOLITHIQUE                      â”‚
â”‚                      (Port 3000)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  /auth/*     â”‚  /events/*   â”‚  /messages/*  â”‚  /users/* â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Prisma Client                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     PostgreSQL        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaractÃ©ristiques :**
- Tous les endpoints dans un seul processus
- Scaling vertical uniquement
- DÃ©ploiement tout-ou-rien
- Single point of failure

### APRÃˆS : Architecture Microservices

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Mobile App    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
        â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Auth Service  â”‚  â”‚Events Service â”‚  â”‚Messages Svc   â”‚
â”‚   (4100)      â”‚  â”‚   (4101)      â”‚  â”‚   (4102)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                  â”‚                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                         â”‚
              â–¼                         â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  PostgreSQL   â”‚        â”‚     Redis     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaractÃ©ristiques :**
- Services indÃ©pendants par domaine
- Scaling horizontal par service
- DÃ©ploiement indÃ©pendant
- Haute disponibilitÃ© (replicas)

---

## ğŸ§© DÃ©coupage en Microservices

### Principe de DÃ©coupage

Le dÃ©coupage suit le **Domain-Driven Design (DDD)** :

| Service | Domaine MÃ©tier | ResponsabilitÃ©s |
|---------|----------------|-----------------|
| **Auth Service** | IdentitÃ© & AccÃ¨s | Login, Register, JWT, Profils, Follow |
| **Events Service** | Calendrier | CRUD Ã©vÃ©nements, Participants, MÃ©dias |
| **Messages Service** | Communication | Conversations, Messages, RÃ©actions |

### Auth Service (Port 4100)

```
services/auth-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts           # Point d'entrÃ©e Fastify
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ auth.ts        # Login, register, refresh
â”‚   â”‚   â”œâ”€â”€ users.ts       # Profils, recherche
â”‚   â”‚   â””â”€â”€ follow.ts      # Follow/unfollow
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ prisma.ts      # Client DB
â”‚       â”œâ”€â”€ auth.ts        # Middleware JWT
â”‚       â””â”€â”€ password.ts    # Hashing bcrypt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

**Endpoints clÃ©s :**
- `POST /auth/login` - Authentification
- `POST /auth/register` - Inscription
- `GET /health` - Health check

### Events Service (Port 4101)

```
services/events-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ events.ts      # CRUD Ã©vÃ©nements
â”‚   â”‚   â”œâ”€â”€ calendars.ts   # Import calendriers
â”‚   â”‚   â”œâ”€â”€ media.ts       # Upload mÃ©dias
â”‚   â”‚   â””â”€â”€ posts.ts       # Posts liÃ©s
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ prisma.ts
â”‚       â””â”€â”€ auth.ts
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

**Endpoints clÃ©s :**
- `GET /events` - Liste Ã©vÃ©nements
- `POST /events` - CrÃ©er Ã©vÃ©nement
- `GET /health` - Health check

### Messages Service (Port 4102)

```
services/messages-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ messages.ts     # Envoi, rÃ©ception
â”‚   â”‚   â””â”€â”€ notifications.ts
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ prisma.ts
â”‚       â””â”€â”€ auth.ts
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

**Endpoints clÃ©s :**
- `GET /messages/conversations` - Liste conversations
- `POST /messages` - Envoyer message
- `GET /health` - Health check

---

## ğŸ”— Communication Inter-Services

### Type de Communication

| Type | Utilisation | Technologie |
|------|-------------|-------------|
| **Synchrone** | RequÃªtes API | REST HTTP |
| **Asynchrone** | Notifications temps rÃ©el | Socket.io + Redis |

### Base de DonnÃ©es PartagÃ©e

Pour ce TP, les services partagent la mÃªme base PostgreSQL (simplification). En production :

```
âœ… Actuel (TP) : BDD partagÃ©e (schÃ©ma Prisma unique)
ğŸ”® Production  : BDD par service + Event Sourcing
```

### SchÃ©ma Prisma PartagÃ©

```
services/shared/
â””â”€â”€ prisma/
    â””â”€â”€ schema.prisma   # SchÃ©ma unique, gÃ©nÃ©rÃ© dans chaque service
```

Chaque service gÃ©nÃ¨re son propre Prisma Client au build :
```dockerfile
RUN npx prisma generate --schema=./shared/prisma/schema.prisma
```

---

## ğŸ³ Dockerisation

### Structure des Dockerfiles

Chaque microservice a le mÃªme pattern :

```dockerfile
FROM node:20-alpine

WORKDIR /app

# DÃ©pendances
COPY services/<service>/package*.json ./
RUN npm install

# SchÃ©ma Prisma partagÃ©
COPY services/shared/prisma ./shared/prisma
RUN npx prisma generate --schema=./shared/prisma/schema.prisma

# Code source
COPY services/<service>/src ./src
COPY services/<service>/tsconfig.json ./

# SÃ©curitÃ© : user non-root
RUN addgroup -g 1001 -S nodejs && adduser -S nodejs -u 1001
USER nodejs

EXPOSE <port>

CMD ["npx", "tsx", "src/index.ts"]
```

**CaractÃ©ristiques :**
- Image Alpine lÃ©gÃ¨re (~200MB)
- ExÃ©cution TypeScript directe (tsx)
- User non-root (sÃ©curitÃ©)
- Multi-stage possible pour production

### Docker Compose Local

**Fichier :** `docker-compose.lifytp.yml`

```yaml
services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: lify
      POSTGRES_PASSWORD: lify
      POSTGRES_DB: lify_dev
    ports:
      - "5433:5432"  # Port LifyTP dÃ©diÃ©
    volumes:
      - pgdata:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6380:6379"  # Port LifyTP dÃ©diÃ©

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    ports:
      - "9100:9000"  # Port LifyTP dÃ©diÃ©
      - "9101:9001"

volumes:
  pgdata:
  minio:

networks:
  lifytp-network:
    driver: bridge
```

**Isolation :** Ports diffÃ©rents de Lify original (5432â†’5433, 6379â†’6380, etc.)

---

## â˜¸ï¸ Architecture Kubernetes

### Vue d'Ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Namespace: lifytp                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Auth        â”‚  â”‚ Events      â”‚  â”‚ Messages    â”‚              â”‚
â”‚  â”‚ Deployment  â”‚  â”‚ Deployment  â”‚  â”‚ Deployment  â”‚              â”‚
â”‚  â”‚ (2 replicas)â”‚  â”‚ (2 replicas)â”‚  â”‚ (2 replicas)â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚         â”‚                â”‚                â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Auth        â”‚  â”‚ Events      â”‚  â”‚ Messages    â”‚              â”‚
â”‚  â”‚ Service     â”‚  â”‚ Service     â”‚  â”‚ Service     â”‚              â”‚
â”‚  â”‚ ClusterIP   â”‚  â”‚ ClusterIP   â”‚  â”‚ ClusterIP   â”‚              â”‚
â”‚  â”‚ :4100       â”‚  â”‚ :4101       â”‚  â”‚ :4102       â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚                  PostgreSQL                          â”‚        â”‚
â”‚  â”‚                  StatefulSet                         â”‚        â”‚
â”‚  â”‚                  (1 replica + PVC)                   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ ConfigMaps   â”‚   â”‚   Secrets    â”‚   â”‚   PVC        â”‚         â”‚
â”‚  â”‚ (3)          â”‚   â”‚   (3)        â”‚   â”‚   (1)        â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Objets Kubernetes UtilisÃ©s

| Objet | QuantitÃ© | RÃ´le |
|-------|----------|------|
| **Namespace** | 1 | Isolation `lifytp` |
| **Deployment** | 5 | Auth, Events, Messages, Redis |
| **StatefulSet** | 1 | PostgreSQL (donnÃ©es persistantes) |
| **Service (ClusterIP)** | 5 | Exposition interne |
| **ConfigMap** | 3 | Configuration non-sensible |
| **Secret** | 3 | Credentials (DB, JWT, MinIO) |
| **PVC** | 1 | Stockage PostgreSQL |

### Fichiers Manifests

```
deploy/
â”œâ”€â”€ namespace.yaml              # Namespace lifytp
â”œâ”€â”€ configmaps/
â”‚   â”œâ”€â”€ auth-config.yaml       # Config auth-service
â”‚   â”œâ”€â”€ events-config.yaml     # Config events-service
â”‚   â””â”€â”€ messages-config.yaml   # Config messages-service
â”œâ”€â”€ secrets/
â”‚   â”œâ”€â”€ db-secret.yaml.example # Template secret DB
â”‚   â”œâ”€â”€ jwt-secret.yaml.example
â”‚   â””â”€â”€ minio-secret.yaml.example
â”œâ”€â”€ deployments/
â”‚   â”œâ”€â”€ auth-deployment.yaml   # 2 replicas auth
â”‚   â”œâ”€â”€ events-deployment.yaml # 2 replicas events
â”‚   â”œâ”€â”€ messages-deployment.yaml
â”‚   â”œâ”€â”€ postgres-statefulset.yaml
â”‚   â””â”€â”€ redis-deployment.yaml
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ auth-service.yaml      # ClusterIP :4100
â”‚   â”œâ”€â”€ events-service.yaml    # ClusterIP :4101
â”‚   â”œâ”€â”€ messages-service.yaml  # ClusterIP :4102
â”‚   â”œâ”€â”€ postgres-service.yaml  # Headless
â”‚   â””â”€â”€ redis-service.yaml
â””â”€â”€ volumes/
    â””â”€â”€ postgres-pvc.yaml      # 5Gi storage
```

### Exemple : Deployment Auth Service

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
  namespace: lifytp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: auth-service
  template:
    metadata:
      labels:
        app: auth-service
    spec:
      containers:
      - name: auth
        image: lifytp-auth-service:latest
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 4100
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: DATABASE_URL
        livenessProbe:
          httpGet:
            path: /health
            port: 4100
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 4100
          initialDelaySeconds: 5
          periodSeconds: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
```

**Points clÃ©s :**
- `replicas: 2` â†’ Haute disponibilitÃ©
- `livenessProbe` â†’ Auto-restart si crash
- `readinessProbe` â†’ Load balancing intelligent
- `RollingUpdate` â†’ DÃ©ploiement sans downtime

### ConfigMaps et Secrets

**ConfigMap (non-sensible) :**
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: auth-config
  namespace: lifytp
data:
  NODE_ENV: "production"
  PORT: "4100"
  JWT_ACCESS_EXPIRES: "7d"
```

**Secret (sensible) :**
```bash
kubectl create secret generic db-secret \
  --from-literal=DATABASE_URL="postgresql://..." \
  --from-literal=POSTGRES_PASSWORD="..." \
  --namespace=lifytp
```

### Persistance (PVC)

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-data
  namespace: lifytp
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
```

---

## ğŸ”„ CI/CD Pipeline

### Architecture CI/CD

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Push     â”‚â”€â”€â”€â”€â–¶â”‚   GitHub    â”‚â”€â”€â”€â”€â–¶â”‚  Kubernetes â”‚
â”‚  develop    â”‚     â”‚   Actions   â”‚     â”‚   Cluster   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                    â–¼             â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   CI    â”‚   â”‚   CD    â”‚
              â”‚ (lint,  â”‚   â”‚ (build, â”‚
              â”‚  build) â”‚   â”‚  push,  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ deploy) â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Workflow CI (develop)

**Trigger :** Push ou PR sur `develop`

```yaml
jobs:
  lint-and-build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
      - run: npm ci
      - run: npm run lint
      - run: npm run typecheck
      - run: npm run build  # Chaque microservice
```

### Workflow CD (production)

**Trigger :** Push d'un tag `v*`

```yaml
jobs:
  build-and-push:
    strategy:
      matrix:
        service: [auth, events, messages]
    steps:
      - uses: docker/build-push-action@v5
        with:
          push: true
          tags: ghcr.io/${{ owner }}/lifytp-${{ service }}:${{ version }}

  deploy-to-kubernetes:
    needs: build-and-push
    steps:
      - run: kubectl apply -f deploy/
      - run: kubectl rollout status deployment/auth-service -n lifytp
```

---

## ğŸ¬ DÃ©monstrations

### DÃ©mo Auto-Healing

**Objectif :** Prouver que Kubernetes recrÃ©e automatiquement les pods supprimÃ©s.

**ProcÃ©dure :**

```bash
# Terminal 1 : Monitoring
kubectl get pods -n lifytp -l app=auth-service -w

# Terminal 2 : Supprimer un pod
kubectl delete pod auth-service-xxx -n lifytp
```

**RÃ©sultat attendu :**
1. Le pod passe en `Terminating`
2. Un nouveau pod est crÃ©Ã© instantanÃ©ment
3. Le nouveau pod passe `Running` en ~9 secondes
4. **Zero downtime** car le 2Ã¨me replica continue de servir

### DÃ©mo Rolling Update

**Objectif :** Mettre Ã  jour sans interruption de service.

**ProcÃ©dure :**

```bash
# Terminal 1 : Monitoring
kubectl get pods -n lifytp -l app=auth-service -w

# Terminal 2 : DÃ©clencher update
kubectl patch deployment auth-service -n lifytp \
  -p '{"spec":{"template":{"metadata":{"annotations":{"version":"v2"}}}}}'
```

**RÃ©sultat attendu :**
1. Nouveaux pods crÃ©Ã©s progressivement
2. Anciens pods terminÃ©s un par un
3. Toujours â‰¥1 pod disponible
4. **~30 secondes** pour update complet

### Test DisponibilitÃ© Pendant Update

```bash
# Pendant le rolling update
while true; do curl -s http://localhost:4100/health && echo " OK"; sleep 1; done
```
Aucune requÃªte ne doit Ã©chouer.

---

## âš ï¸ DifficultÃ©s et Solutions

### 1. Images Docker Non TrouvÃ©es

**ProblÃ¨me :** `ImagePullBackOff` - images GHCR non disponibles en local

**Solution :**
```yaml
# Avant (production)
imagePullPolicy: Always

# AprÃ¨s (dev local)
imagePullPolicy: IfNotPresent  # ou Never
```

### 2. Imports CassÃ©s dans Microservices

**ProblÃ¨me :** Routes copiÃ©es du monolithe avec imports relatifs invalides

**Solution :** CrÃ©er les fichiers `lib/` locaux dans chaque service :
- `prisma.ts` - Client Prisma
- `auth.ts` - Middleware JWT
- `password.ts` - Hashing

### 3. Secrets Non CrÃ©Ã©s

**ProblÃ¨me :** Pods en `CrashLoopBackOff` car secrets manquants

**Solution :** CrÃ©er les secrets AVANT les deployments :
```bash
kubectl create secret generic db-secret --from-literal=... -n lifytp
```

### 4. Espace dans ClÃ© ConfigMap

**ProblÃ¨me :** `JWT_RE FRESH_EXPIRES` au lieu de `JWT_REFRESH_EXPIRES`

**Solution :** VÃ©rifier les fichiers YAML avec un linter

### 5. Health Checks Ã‰chouent

**ProblÃ¨me :** `wget` non disponible dans image Alpine

**Solution :** Utiliser `curl` ou installer `wget` :
```dockerfile
RUN apk add --no-cache wget
```

---

## ğŸ“Š RÃ©capitulatif

### Ã‰tat Final Kubernetes

| Ressource | QuantitÃ© | Status |
|-----------|----------|--------|
| **Pods** | 8 | âœ… Running |
| **Services** | 5 | âœ… ClusterIP |
| **Deployments** | 4 | âœ… Ready |
| **StatefulSet** | 1 | âœ… Ready |
| **ConfigMaps** | 3 | âœ… Created |
| **Secrets** | 3 | âœ… Created |
| **PVC** | 1 | âœ… Bound |

### CapacitÃ©s DÃ©montrÃ©es

| CapacitÃ© | DÃ©mo | RÃ©sultat |
|----------|------|----------|
| **Auto-healing** | Pod supprimÃ© â†’ recrÃ©Ã© | âœ… ~9s |
| **Rolling update** | Update sans downtime | âœ… ~30s |
| **Load balancing** | 2 replicas actifs | âœ… |
| **Health probes** | Liveness + Readiness | âœ… |
| **Secrets management** | Credentials chiffrÃ©s | âœ… |
| **Configuration externe** | ConfigMaps | âœ… |

---

## ğŸ“š RÃ©fÃ©rences

- **README principal :** [README.md](README.md)
- **Manifests K8s :** [deploy/](deploy/)
- **Microservices :** [services/](services/)
- **CI/CD Workflows :** [.github/workflows/](.github/workflows/)
